{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def load_predictions_data():\n",
    "    predictions_path=os.path.join(\"datasets\", \"predictions_prod_smallest.csv\")\n",
    "    return pd.read_csv(predictions_path, dtype={\"predictions_route_id\": str, \"predictions_stop_id\": str})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_predictions_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predictions_id</th>\n",
       "      <th>predictions_trip_id</th>\n",
       "      <th>predictions_arrival_time</th>\n",
       "      <th>predictions_boarding_status</th>\n",
       "      <th>predictions_departure_time</th>\n",
       "      <th>predictions_stop_id</th>\n",
       "      <th>predictions_stop_sequence</th>\n",
       "      <th>predictions_stops_away</th>\n",
       "      <th>predictions_vehicle_event_id</th>\n",
       "      <th>predictions_file_timestamp</th>\n",
       "      <th>predictions_route_id</th>\n",
       "      <th>predictions_vehicle_id</th>\n",
       "      <th>predictions_direction_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>648187443</td>\n",
       "      <td>39783376</td>\n",
       "      <td>1.553863e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.553863e+09</td>\n",
       "      <td>70040</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10212508</td>\n",
       "      <td>1553862833</td>\n",
       "      <td>Blue</td>\n",
       "      <td>B-545C365A</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>648187455</td>\n",
       "      <td>39988585-20:30-FKenmoreStMaryC</td>\n",
       "      <td>1.553863e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.553863e+09</td>\n",
       "      <td>70203</td>\n",
       "      <td>620</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10212521</td>\n",
       "      <td>1553862833</td>\n",
       "      <td>Green-C</td>\n",
       "      <td>G-10142</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>648187514</td>\n",
       "      <td>40033949</td>\n",
       "      <td>1.553864e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.553864e+09</td>\n",
       "      <td>70007</td>\n",
       "      <td>30</td>\n",
       "      <td>8.0</td>\n",
       "      <td>10214673</td>\n",
       "      <td>1553862833</td>\n",
       "      <td>Orange</td>\n",
       "      <td>O-545C36A0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>648187604</td>\n",
       "      <td>ADDED-1553782585</td>\n",
       "      <td>1.553864e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.553864e+09</td>\n",
       "      <td>70156</td>\n",
       "      <td>580</td>\n",
       "      <td>9.0</td>\n",
       "      <td>10214713</td>\n",
       "      <td>1553862833</td>\n",
       "      <td>Green-D</td>\n",
       "      <td>G-10152</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>648187732</td>\n",
       "      <td>40033948</td>\n",
       "      <td>1.553863e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.553863e+09</td>\n",
       "      <td>70005</td>\n",
       "      <td>20</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10213047</td>\n",
       "      <td>1553862833</td>\n",
       "      <td>Orange</td>\n",
       "      <td>O-545C364E</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   predictions_id             predictions_trip_id  predictions_arrival_time  \\\n",
       "0       648187443                        39783376              1.553863e+09   \n",
       "1       648187455  39988585-20:30-FKenmoreStMaryC              1.553863e+09   \n",
       "2       648187514                        40033949              1.553864e+09   \n",
       "3       648187604                ADDED-1553782585              1.553864e+09   \n",
       "4       648187732                        40033948              1.553863e+09   \n",
       "\n",
       "  predictions_boarding_status  predictions_departure_time predictions_stop_id  \\\n",
       "0                         NaN                1.553863e+09               70040   \n",
       "1                         NaN                1.553863e+09               70203   \n",
       "2                         NaN                1.553864e+09               70007   \n",
       "3                         NaN                1.553864e+09               70156   \n",
       "4                         NaN                1.553863e+09               70005   \n",
       "\n",
       "   predictions_stop_sequence  predictions_stops_away  \\\n",
       "0                         10                     1.0   \n",
       "1                        620                     1.0   \n",
       "2                         30                     8.0   \n",
       "3                        580                     9.0   \n",
       "4                         20                     2.0   \n",
       "\n",
       "   predictions_vehicle_event_id  predictions_file_timestamp  \\\n",
       "0                      10212508                  1553862833   \n",
       "1                      10212521                  1553862833   \n",
       "2                      10214673                  1553862833   \n",
       "3                      10214713                  1553862833   \n",
       "4                      10213047                  1553862833   \n",
       "\n",
       "  predictions_route_id predictions_vehicle_id  predictions_direction_id  \n",
       "0                 Blue             B-545C365A                         1  \n",
       "1              Green-C                G-10142                         1  \n",
       "2               Orange             O-545C36A0                         1  \n",
       "3              Green-D                G-10152                         1  \n",
       "4               Orange             O-545C364E                         1  "
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "for train_index, test_index in split.split(data, data[\"predictions_route_id\"]):\n",
    "    strat_train_set = data.loc[train_index]\n",
    "    strat_test_set = data.loc[test_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "\n",
    "class DropColumnsTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, include_stops_away=False, include_route_id=False):\n",
    "        self.include_stops_away = include_stops_away\n",
    "        self.include_route_id = include_route_id\n",
    "        \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        return X.drop([\"predictions_id\", \n",
    "                       \"predictions_trip_id\", \n",
    "                       \"predictions_stop_sequence\",\n",
    "                       \"predictions_vehicle_event_id\",\n",
    "                       \"predictions_vehicle_id\",\n",
    "                       \"predictions_file_timestamp\",],\n",
    "                      axis=1)\n",
    "\n",
    "class IsStoppedTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        result = X.copy()\n",
    "        result['is_stopped'] = X['predictions_boarding_status'].notnull()\n",
    "        return result.drop('predictions_boarding_status', axis=1)\n",
    "\n",
    "class TimestampTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        new_data = X.copy()\n",
    "        datetimes = new_data['predictions_file_timestamp'].apply(\n",
    "            lambda x: datetime.fromtimestamp(x),\n",
    "        )\n",
    "        predictions_day_of_week = datetimes.apply(lambda x: x.weekday())\n",
    "        predictions_time_bin = datetimes.apply(self._timestamp_bin)\n",
    "        new_data['predictions_day_of_week'] = predictions_day_of_week\n",
    "        new_data['predictions_time_bin'] = predictions_time_bin\n",
    "        return new_data\n",
    "    \n",
    "    def _timestamp_bin(self, timestamp):\n",
    "        return timestamp.hour * 4 + timestamp.minute // 15\n",
    "\n",
    "class ColumnOneHotEncoder(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self, column):\n",
    "        self.column = column\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        enc = OneHotEncoder()\n",
    "        one_hotted = enc.fit_transform(X[self.column].values.reshape(-1,1))\n",
    "        return np.concatenate((X.drop(self.column, axis=1), one_hotted), axis=1)\n",
    "    \n",
    "class DebugTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        print(X.info())\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "one_hots = ColumnTransformer([\n",
    "    ('1hot', OneHotEncoder(), ['predictions_stop_id', \n",
    "                               'predictions_route_id', \n",
    "                               'predictions_day_of_week', \n",
    "                               'predictions_time_bin'])\n",
    "])\n",
    "\n",
    "predictions_pipeline = Pipeline([\n",
    "    ('timestamp', TimestampTransformer()),\n",
    "    ('is_stopped', IsStoppedTransformer()),\n",
    "    ('drop', DropColumnsTransformer()),\n",
    "    ('1hot', one_hots)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitted = predictions_pipeline.fit_transform(strat_train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 1., 0., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "        1., 0.]])"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fitted[0].toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
