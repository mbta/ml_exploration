{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predictions ML Project\n",
    "\n",
    "This ML Project uses one week's worth of Prediction Analyzer predictions and vehicle_events as source data. The data has some potential ML features like the stop_id, route_id, timestamp, etc, as well as the predictions we made and the observed times of the actual arrival and departure events. This data was chosen because there's a lot of it and it's easy to obtain, and therefore a good way to test out the ML process, not because we expected particularly great results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Obtaining the data\n",
    "\n",
    "The data is available in a public S3 bucket, about 140MB zipped and about 1GB unzipped, and about 7 million rows altogether. The following code downloads it (if it detects it doesn't exist already) to a `datasets/` directory. It then reads it into a Pandas DataFrame called `pristine_data` and makes a copy of it called `data`. Since it takes some time to unzip the file and read it into memory, we always work on `data`, and if we want to scrap our changes and start over, we can re-run all the cells, and it will copy over `data = pristine_data.copy()` once again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from six.moves import urllib\n",
    "\n",
    "DOWNLOAD_URL = \"https://s3.amazonaws.com/mbta-subway-realtime/datasets/predictions.csv.gz\"\n",
    "LOCAL_DIR = os.path.join(\"datasets\")\n",
    "LOCAL_FILE = os.path.join(LOCAL_DIR, \"predictions.csv.gz\")\n",
    "\n",
    "def fetch_predictions_data():\n",
    "    if not os.path.isdir(LOCAL_DIR):\n",
    "        os.makedirs(LOCAL_DIR)\n",
    "        \n",
    "    if not os.path.isfile(LOCAL_FILE):\n",
    "        print(\"Downloading predictions.csv.gz\")\n",
    "        urllib.request.urlretrieve(DOWNLOAD_URL, LOCAL_FILE)\n",
    "        print(\"Downloaded.\")\n",
    "\n",
    "def load_predictions_data():\n",
    "    return pd.read_csv(\n",
    "        LOCAL_FILE, \n",
    "        dtype={\"predictions_route_id\": str, \"predictions_stop_id\": str},\n",
    "        compression='gzip'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    pristine_data\n",
    "except NameError:\n",
    "    fetch_predictions_data()\n",
    "    pristine_data = load_predictions_data()\n",
    "\n",
    "data = pristine_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>predictions_id</th>\n",
       "      <th>predictions_trip_id</th>\n",
       "      <th>predictions_arrival_time</th>\n",
       "      <th>predictions_boarding_status</th>\n",
       "      <th>predictions_departure_time</th>\n",
       "      <th>predictions_stop_id</th>\n",
       "      <th>predictions_stop_sequence</th>\n",
       "      <th>predictions_stops_away</th>\n",
       "      <th>predictions_vehicle_event_id</th>\n",
       "      <th>predictions_file_timestamp</th>\n",
       "      <th>predictions_route_id</th>\n",
       "      <th>predictions_vehicle_id</th>\n",
       "      <th>predictions_direction_id</th>\n",
       "      <th>ve_id</th>\n",
       "      <th>ve_arrival_time</th>\n",
       "      <th>ve_departure_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>648187443</td>\n",
       "      <td>39783376</td>\n",
       "      <td>1.553863e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.553863e+09</td>\n",
       "      <td>70040</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10212508</td>\n",
       "      <td>1553862833</td>\n",
       "      <td>Blue</td>\n",
       "      <td>B-545C365A</td>\n",
       "      <td>1</td>\n",
       "      <td>10212508</td>\n",
       "      <td>1.553863e+09</td>\n",
       "      <td>1.553863e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>648187455</td>\n",
       "      <td>39988585-20:30-FKenmoreStMaryC</td>\n",
       "      <td>1.553863e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.553863e+09</td>\n",
       "      <td>70203</td>\n",
       "      <td>620</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10212521</td>\n",
       "      <td>1553862833</td>\n",
       "      <td>Green-C</td>\n",
       "      <td>G-10142</td>\n",
       "      <td>1</td>\n",
       "      <td>10212521</td>\n",
       "      <td>1.553863e+09</td>\n",
       "      <td>1.553863e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>648187514</td>\n",
       "      <td>40033949</td>\n",
       "      <td>1.553864e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.553864e+09</td>\n",
       "      <td>70007</td>\n",
       "      <td>30</td>\n",
       "      <td>8.0</td>\n",
       "      <td>10214673</td>\n",
       "      <td>1553862833</td>\n",
       "      <td>Orange</td>\n",
       "      <td>O-545C36A0</td>\n",
       "      <td>1</td>\n",
       "      <td>10214673</td>\n",
       "      <td>1.553864e+09</td>\n",
       "      <td>1.553864e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>648187604</td>\n",
       "      <td>ADDED-1553782585</td>\n",
       "      <td>1.553864e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.553864e+09</td>\n",
       "      <td>70156</td>\n",
       "      <td>580</td>\n",
       "      <td>9.0</td>\n",
       "      <td>10214713</td>\n",
       "      <td>1553862833</td>\n",
       "      <td>Green-D</td>\n",
       "      <td>G-10152</td>\n",
       "      <td>1</td>\n",
       "      <td>10214713</td>\n",
       "      <td>1.553864e+09</td>\n",
       "      <td>1.553864e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>648187732</td>\n",
       "      <td>40033948</td>\n",
       "      <td>1.553863e+09</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.553863e+09</td>\n",
       "      <td>70005</td>\n",
       "      <td>20</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10213047</td>\n",
       "      <td>1553862833</td>\n",
       "      <td>Orange</td>\n",
       "      <td>O-545C364E</td>\n",
       "      <td>1</td>\n",
       "      <td>10213047</td>\n",
       "      <td>1.553863e+09</td>\n",
       "      <td>1.553863e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   predictions_id             predictions_trip_id  predictions_arrival_time  \\\n",
       "0       648187443                        39783376              1.553863e+09   \n",
       "1       648187455  39988585-20:30-FKenmoreStMaryC              1.553863e+09   \n",
       "2       648187514                        40033949              1.553864e+09   \n",
       "3       648187604                ADDED-1553782585              1.553864e+09   \n",
       "4       648187732                        40033948              1.553863e+09   \n",
       "\n",
       "  predictions_boarding_status  predictions_departure_time predictions_stop_id  \\\n",
       "0                         NaN                1.553863e+09               70040   \n",
       "1                         NaN                1.553863e+09               70203   \n",
       "2                         NaN                1.553864e+09               70007   \n",
       "3                         NaN                1.553864e+09               70156   \n",
       "4                         NaN                1.553863e+09               70005   \n",
       "\n",
       "   predictions_stop_sequence  predictions_stops_away  \\\n",
       "0                         10                     1.0   \n",
       "1                        620                     1.0   \n",
       "2                         30                     8.0   \n",
       "3                        580                     9.0   \n",
       "4                         20                     2.0   \n",
       "\n",
       "   predictions_vehicle_event_id  predictions_file_timestamp  \\\n",
       "0                      10212508                  1553862833   \n",
       "1                      10212521                  1553862833   \n",
       "2                      10214673                  1553862833   \n",
       "3                      10214713                  1553862833   \n",
       "4                      10213047                  1553862833   \n",
       "\n",
       "  predictions_route_id predictions_vehicle_id  predictions_direction_id  \\\n",
       "0                 Blue             B-545C365A                         1   \n",
       "1              Green-C                G-10142                         1   \n",
       "2               Orange             O-545C36A0                         1   \n",
       "3              Green-D                G-10152                         1   \n",
       "4               Orange             O-545C364E                         1   \n",
       "\n",
       "      ve_id  ve_arrival_time  ve_departure_time  \n",
       "0  10212508     1.553863e+09       1.553863e+09  \n",
       "1  10212521     1.553863e+09       1.553863e+09  \n",
       "2  10214673     1.553864e+09       1.553864e+09  \n",
       "3  10214713     1.553864e+09       1.553864e+09  \n",
       "4  10213047     1.553863e+09       1.553863e+09  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparing the data\n",
    "\n",
    "There are a variety of ways to clean up the data. Some things we need to take care of: handle null values and remove outliers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Restrict the size\n",
    "\n",
    "Some algorithms (in particular, Random Forest and SVM) can't seem to handle our 7 million rows very well. Linear regression, on the other hand is able to train in just a couple minutes on the entire dataset. We often restrict the data to just a certain route, for perforamnce reasons, but also because they behave rather differently, and fitting  all of them might not be the best approach anyway. Depending on whether and how you want to restrict the data, adjust or comment out the following line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[data[\"predictions_route_id\"] == 'Mattapan']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Arrivals vs. Departures and handling nulls\n",
    "\n",
    "Not all predictions have both arrivals and departures. We don't predict a departure for the last stop on a trip, and conversely we don't predict an arrival for the first.\n",
    "\n",
    "In addition, at terminals beginning a route we use the departures: (\"The next train to Braintree departs in 4 minutes\"). At stations along a route we use arrivals: (\"The next train to Braintree arrives in 4 minutes\").\n",
    "\n",
    "For this investigation we decided to focus on arrival times, and so removed any rows with NULL arrivals, as well as arrival predictions for more than 30 minutes away or earlier than 30 seconds ago (train sitting at platform), which we don't score ourselves on with the Prediction Analyzer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.dropna(subset=[\"predictions_arrival_time\", \"ve_arrival_time\"])\n",
    "data = data[data[\"predictions_arrival_time\"] - data[\"predictions_file_timestamp\"] < 30*60]\n",
    "data = data[data[\"predictions_arrival_time\"] - data[\"predictions_file_timestamp\"] > -30]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predicting our error\n",
    "\n",
    "There's different approaches to what our labels (and therefore ML-predicted values) could be. We could try to directly predict the arrival times, but with this dataset we likely don't have enough features (e.g. where the trains are or where they're going) to do a great job of it.\n",
    "\n",
    "Instead, what we'll do is calculate the _error_ we made in our own predictions, and then see if an ML model can do a good job of predicting that error. This would imply a persistent bias in how RTR makes predictions, and that accuracy could be improved by either fixing that bias or even just running the predictions through the ML-model to adjust them.\n",
    "\n",
    "We also throw out rows with very large errors as those tend to be from unanticipated incidents that can't be predicted well anyway."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"predictions_error\"] = data[\"ve_arrival_time\"] - data[\"predictions_arrival_time\"]\n",
    "data = data[data[\"predictions_error\"] >= -600]\n",
    "data = data[data[\"predictions_error\"] <= 600]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the prediction errors we make:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "data[\"predictions_error\"].hist(bins=50, figsize=(15,5))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set aside a test set\n",
    "\n",
    "Before doing any serious investigation or further modifications to the data for different algortihms, we should set aside a test set.\n",
    "\n",
    "We use a `StratifiedShuffleSplit` to ensure that the randomly selected training and test sets have the same proportion of data in each route."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "for train_index, test_index in split.split(data, data[\"predictions_route_id\"]):\n",
    "    strat_train_set = data.iloc[train_index]\n",
    "    strat_test_set = data.iloc[test_index]\n",
    "    \n",
    "train_labels = strat_train_set[\"predictions_error\"].copy()\n",
    "test_labels = strat_test_set[\"predictions_error\"].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Transformations\n",
    "\n",
    "Different algorithms call for transforming the data in different ways. For example, SVMs should have their features standardized and centered. Or linear regressions can't handle unix epoch file timestamps well, and work better with discretizing them into time window bins.\n",
    "\n",
    "Scikit-learn aids these transformations with the concept of a \"Pipeline\" that you run your data through. It provides Transformers and also allows you to write your own to fit into the pipeline. This makes it quite easy to fiddle with the pipeline, the transformers, and the characteristics of the transformers (\"hyperparameters\").\n",
    "\n",
    "To write your own Transformer you write a class that inherits from Scikit-learn's classes, and provide three methods. You can use the constructor, `__init__` to present hyperparameters for the user to tune. `fit` sets internal state based on the data (e.g. this is where a learning algorithm would train), and `transform` takes the data as an argument and returns a _new copy_ of the transformed data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `IsStoppedTransformer`\n",
    "\n",
    "This transformer checks the `predictions_boarding_status` column, which can be either NULL or something like \"Stopped 4 stops away\", and generates a boolean feature `is_stopped` from it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class IsStoppedTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        result = X.copy()\n",
    "        result['is_stopped'] = X['predictions_boarding_status'].notnull()\n",
    "        return result.drop('predictions_boarding_status', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `TimestampTransformer`\n",
    "\n",
    "This transformer takes the `predictions_file_timestamp` value, which is a UNIX epoch value, and sets two columns: a `predictions_day_of_week` (from 0 = Monday to 6 = Sunday), and `predictions_time_bin`, which starts at `0` at midnight and increments for every 15 minuts. E.g., a prediction at 11:35AM would be `46`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from datetime import datetime\n",
    "\n",
    "class TimestampTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        new_data = X.copy()\n",
    "        datetimes = new_data['predictions_file_timestamp'].apply(\n",
    "            lambda x: datetime.fromtimestamp(x),\n",
    "        )\n",
    "        predictions_day_of_week = datetimes.apply(lambda x: x.weekday())\n",
    "        predictions_time_bin = datetimes.apply(self._timestamp_bin)\n",
    "        new_data['predictions_day_of_week'] = predictions_day_of_week\n",
    "        new_data['predictions_time_bin'] = predictions_time_bin\n",
    "        return new_data\n",
    "    \n",
    "    def _timestamp_bin(self, timestamp):\n",
    "        return timestamp.hour * 4 + timestamp.minute // 15"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `AccuracyBinTransformer`\n",
    "\n",
    "This takes the difference of `predictions_arrival_time` and `predictions_file_timestamp` UNIX times (which gives the predicted number of seconds \"from now\" that the train will arrive), and bins it according to the groupings that drive the MBTA's accuracy data: \"0-3 minutes\", \"3-6 minutes\", \"6-12 minutes\", and \"12-30 minutes\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class AccuracyBinTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        copy = X.copy()\n",
    "        copy[\"accuracy_bin\"] = (copy['predictions_arrival_time'] - copy['predictions_file_timestamp']).apply(self._accuracy_bin)\n",
    "        return copy\n",
    "        \n",
    "    def _accuracy_bin(self, seconds):\n",
    "        if seconds < -30:\n",
    "            return 'na-'\n",
    "        elif -30 <= seconds < 180:\n",
    "            return '0-3'\n",
    "        elif 180 <= seconds < 360:\n",
    "            return '3-6'\n",
    "        elif 360 <= seconds < 720:\n",
    "            return '6-12'\n",
    "        elif 720 <= seconds < 1800:\n",
    "            return '12-30'\n",
    "        else:\n",
    "            return 'na+'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Other transformers\n",
    "\n",
    "We wrote a `DebugTransformer` that simply prints a bit of the data and returns it unchanged. This is an easy way to get a peek at what's going on with the data through the pipeline.\n",
    "\n",
    "We also wrote a `DenseMatrixTransformer` which just calls `.toarray()` on the data it gets. This has the effect of converting a sparse matrix (which you often get after One Hot encoding a feature) into a dense one, which is required by the SVM algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "class DebugTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        print(X.info())\n",
    "        return X\n",
    "\n",
    "class DenseMatrixTransformer(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        return X.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Putting it together in a Pipeline\n",
    "\n",
    "You can now put together these transformers in a pipeline.\n",
    "\n",
    "In addition to our custom transformers, we use some built-in ones:\n",
    "\n",
    "* `ColumnTransformer` - this runs its transformers in parallel, passing a specified subset of columns to each one, and then concatenates the results.\n",
    "* `passthrough` - this enumerates the set of columns the `ColumnTransformer` should \"pass through\" untouched to the output. It serves as a whitelist of columns to allow in the final data set.\n",
    "* `OneHotEncoder` - this will transform one column of N unique values into N columns, representing each of those values. Each row will then have a `1` in the column corresponding to the value it used to have, and `0` in all the others. In the `ColumnTransformer` we specify which of our input columns we want to have this done to.\n",
    "* `PolynomialFeatures` - this will, depending on its configuration, multiply the features together in various ways, which is an easy way to allow a linear algorithm (e.g. linear regression) to handle non-linear relationships between features.\n",
    "* `StandardScaler` - this scales the features to have a mean of zero and variance of one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import PolynomialFeatures, StandardScaler, OneHotEncoder\n",
    "\n",
    "passthrough_features = [\n",
    "    'is_stopped',\n",
    "    'predictions_stops_away',\n",
    "#     'predictions_direction_id'  # highly correlated with stop_id\n",
    "]\n",
    "\n",
    "column_transformer = ColumnTransformer([\n",
    "    ('pass', 'passthrough', passthrough_features),\n",
    "    ('1hot', OneHotEncoder(), [\n",
    "        'predictions_stop_id', \n",
    "#         'predictions_route_id', # can't use this if dataset is restricted to one route_id\n",
    "        'predictions_day_of_week',\n",
    "        'accuracy_bin',\n",
    "        'predictions_time_bin'\n",
    "    ])\n",
    "])\n",
    "\n",
    "predictions_pipeline = Pipeline([\n",
    "    ('timestamp', TimestampTransformer()),\n",
    "    ('is_stopped', IsStoppedTransformer()),\n",
    "    ('accuracy_bin', AccuracyBinTransformer()),\n",
    "    ('col_transformer', column_transformer),\n",
    "#     ('poly', PolynomialFeatures(degree=2)),  # takes too long when stop_ids are one-hotted\n",
    "#     ('dense_matrix', DenseMatrixTransformer()), # necessary when using StandardScaler\n",
    "#     ('std_scaler', StandardScaler()),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train the data!\n",
    "\n",
    "And now the fun begins.\n",
    "\n",
    "With the pipeline in place, and easily tweakable, we can run train different learning algorithms on it, and then visualize their results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_data = predictions_pipeline.fit_transform(strat_train_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set the `algo` variable to which one this notebook should run when clicking \"Run All\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "algo = 'random_forest'  # can change to 'random_forest' or 'svm'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear regression\n",
    "\n",
    "The fastest algorithm is a simple linear regression. It also has the benefits of having easily interpretable results. It's always a good place to start."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "if algo == 'linear_regression':\n",
    "    lin_reg = LinearRegression()\n",
    "    lin_reg.fit(transformed_data, train_labels)\n",
    "    predictions = lin_reg.predict(transformed_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One easy way to see how well the model worked is its root mean squared error:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "if algo == 'linear_regression':\n",
    "    lin_mse = mean_squared_error(train_labels, predictions)\n",
    "    lin_rmse = np.sqrt(lin_mse)\n",
    "    print(lin_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we can see the model's bias (intercept):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "if algo == 'linear_regression':\n",
    "    lin_reg.intercept_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and its coefficients:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "if algo == 'linear_regression':\n",
    "    ct = predictions_pipeline.named_steps['col_transformer']\n",
    "    (_, _, passthrough_cols) = ct.transformers[0]\n",
    "    onehot_cols = ct.named_transformers_['1hot'].get_feature_names()\n",
    "\n",
    "    features = passthrough_cols + onehot_cols.tolist()\n",
    "    sorted(zip(lin_reg.coef_, features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random forest\n",
    "\n",
    "This algorithm was tolerable to train on a single route, but not on the whole dataset. And it gave very good results, albeit not ones that are interpretable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "if algo == 'random_forest':\n",
    "    rand_forest = RandomForestRegressor(n_estimators=10, n_jobs=8)\n",
    "    rand_forest.fit(transformed_data, train_labels)\n",
    "    predictions = rand_forest.predict(transformed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33.348265674445706\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "if algo == 'random_forest':\n",
    "    forest_mse = mean_squared_error(train_labels, predictions)\n",
    "    forest_rmse = np.sqrt(forest_mse)\n",
    "    print(forest_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "if algo == 'random_forest':\n",
    "    ct = predictions_pipeline.named_steps['col_transformer']\n",
    "    (_, _, passthrough_cols) = ct.transformers[0]\n",
    "    onehot_cols = ct.named_transformers_['1hot'].get_feature_names()\n",
    "\n",
    "    features = passthrough_cols + onehot_cols.tolist()\n",
    "\n",
    "    sorted(zip(rand_forest.feature_importances_, features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support vector machines\n",
    "\n",
    "SVMs can be used as a classifier or a regressor (SVR in that case), and can use a linear or polynomial (or other) kernel.\n",
    "\n",
    "In our testing, we couldn't get it to complete other than with a very small data set (e.g. Mattapan, but no other route)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVR\n",
    "\n",
    "if algo == 'svm':\n",
    "    lsvm = LinearSVR(epsilon=0, dual=False, loss='squared_epsilon_insensitive')\n",
    "    lsvm.fit(fitted, train_labels)\n",
    "    predictions = lsvm.predict(fitted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "if algo == 'svm':\n",
    "    lsvm_mse = mean_squared_error(train_labels, predictions)\n",
    "    lsvm_rmse = np.sqrt(lsvm_mse)\n",
    "    lsvm_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "if algo == 'svm':\n",
    "    ct = predictions_pipeline.named_steps['col_transformer']\n",
    "    (_, _, passthrough_cols) = ct.transformers[0]\n",
    "    onehot_cols = ct.named_transformers_['1hot'].get_feature_names()\n",
    "\n",
    "    features = passthrough_cols + onehot_cols.tolist()\n",
    "\n",
    "    sorted(zip(lsvm.coef_, features))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or with a polynomial kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVR\n",
    "\n",
    "if algo == 'svm':\n",
    "    svm_poly_reg = SVR(kernel=\"poly\", degree=2, epsilon=30)\n",
    "    svm_poly_reg.fit(fitted, train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize the results\n",
    "\n",
    "Finally, let's look at the results of the model. Since we were predicting the error of our predictions, we can generate New and Improvedâ„¢ (hopefully) predictions, by predicting an error for each row and adding it to the existing prediction.\n",
    "\n",
    "We can then score each row as \"accurate\" or not for the original prediction and the ML-adjusted prediction, according to the tolerances we use in the Prediction Analyzer, and then chart our accuracy rates.\n",
    "\n",
    "We should choose if we want to do this against our `strat_training_set` (the data we trained against, to visualize it), or `strat_test_set` (the data we held out at the beginning, to see our final results)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "viz_data = strat_train_set.copy()  # or strat_test_set.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "if algo == 'linear_regression':\n",
    "    model = lin_reg\n",
    "elif algo == 'random_forest':\n",
    "    model = rand_forest\n",
    "elif algo == 'svm':\n",
    "    model = lsvm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_viz_data = predictions_pipeline.fit_transform(viz_data)\n",
    "predicted_errors = model.predict(transformed_viz_data)\n",
    "viz_data = AccuracyBinTransformer().transform(viz_data)\n",
    "viz_data[\"ml_arrival_time\"] = viz_data.loc[:, \"predictions_arrival_time\"] + predicted_errors\n",
    "viz_data[\"ml_error\"] = viz_data.loc[:, \"ve_arrival_time\"] - viz_data.loc[:, \"ml_arrival_time\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also compare the RMSE of the original data to our adjusted data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(107.68942336443116, 33.348265674231435)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "predictions_rmse = np.sqrt(viz_data[\"predictions_error\"].apply(lambda x: x**2).sum() / len(viz_data[\"predictions_error\"]))\n",
    "ml_rmse = np.sqrt(viz_data[\"ml_error\"].apply(lambda x: x**2).sum() / len(viz_data[\"ml_error\"]))\n",
    "(predictions_rmse, ml_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_accurate(acc_bin, error):\n",
    "    if acc_bin == '0-3':\n",
    "        return -60 <= error <= 60\n",
    "    elif acc_bin == '3-6':\n",
    "        return -90 <= error <= 120\n",
    "    elif acc_bin == '6-12':\n",
    "        return -150 <= error <= 210\n",
    "    elif acc_bin == '12-20':\n",
    "        return -240 <= error <= 360\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def is_accurate_vector(acc_bins, errors):\n",
    "    return (acc_bins.str.match('0-3') & (errors >= -60) & (errors <= 60)) | \\\n",
    "        (acc_bins.str.match('3-6') & (errors >= -90) & (errors <= 120)) | \\\n",
    "        (acc_bins.str.match('6-12') & (errors >= -150) & (errors <= 210)) | \\\n",
    "        (acc_bins.str.match('12-30') & (errors >= -240) & (errors <= 360))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "viz_data[\"ml_accuracy\"] = is_accurate_vector(viz_data[\"accuracy_bin\"], viz_data[\"ml_error\"])\n",
    "viz_data[\"prediction_accuracy\"] = is_accurate_vector(viz_data[\"accuracy_bin\"], viz_data[\"predictions_error\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Depending on how the data was limited, you may want to group by `prediction_stop_id` instead of `predictions_route_id`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_acc = viz_data.groupby('predictions_route_id')['prediction_accuracy'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "ml_acc = viz_data.groupby('predictions_route_id')['ml_accuracy'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x11dfb49e8>"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAsYAAAFmCAYAAABunFzGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAFoZJREFUeJzt3X+w53dd2PvnKwmwM/JrmmynHTa62zYIwWALKRWjt7ZpZ4LOJLaFmggqxTZjLB1baUs6OpYitUWddkRDKR3bFA3mEr23ZGoKd6yoVQhko0ADJGWFCIvea5oiFSmQyPv+sSf0sCzsITlnz8nJ4zFzJufz+by/3+/r8MfOcz68v9/vrLUCAIBHurN2ewAAANgLhDEAACSMAQCgEsYAAFAJYwAAqIQxAABUwhgAACphDAAAlTAGAICqztmtFz7vvPPW4cOHd+vlAQB4hLj99tv/+1rr4OnW7VoYHz58uKNHj+7WywMA8AgxM7+1lXW2UgAAQMIYAAAqYQwAANUu7jEGAODMuO+++zp+/Hif/OQnd3uUHXXgwIEOHTrUox71qAf1eGEMALDPHT9+vMc97nEdPny4mdntcXbEWqt7772348ePd+TIkQf1HKfdSjEz/3Zmfndm7vgC12dmXjUzx2bm3TPzjAc1CQAAO+KTn/xk55577r6N4qqZ6dxzz31Id8W3ssf4+uqyL3L9OdUFGz9XV//qQU8DAMCO2M9R/ICH+jeeNozXWr9S/Y8vsuSK6nXrhFurJ87MH39IUwEAwBm2HXuMn1R9eNPx8Y1zv3Pywpm5uhN3lfvyL//ybXhpAAC+VIev/fltfb67//k3bevzbcVjH/vYPv7xj2/rc57Rj2tba712rXXxWuvigwdP+618AAA8gvzhH/7hrr7+doTxR6rzNx0f2jgHAABV3X333T3lKU/p+c9/fk996lN77nOf2yc+8YkOHz7cS1/60p7xjGd000039Zu/+ZtddtllPfOZz+zrv/7ru/POO6v64Ac/2LOf/ewuuuiivv/7v39HZtyOrRQ3Vy+emRurP1d9bK31edsoANgGL3vCbk8Ap/ayj+32BDwM3HXXXf3kT/5kl1xySS960Yt69atfXdW5557br//6r1d16aWX9prXvKYLLrigt7/97X33d393v/iLv9j3fM/3dM011/Tt3/7tXXfddTsy32nDeGZ+pvqG6ryZOV794+pRVWut11S3VN9YHas+Uf2NHZkUAICHtfPPP79LLrmkqhe84AW96lWvqupbvuVbqvr4xz/eW9/61p73vOd99jGf+tSnqvq1X/u1fu7nfq6qb/u2b+ulL33pts932jBea111muur+tvbNhEAAPvSyR+n9sDxl33Zl1X1mc98pic+8Ym9853v3NLjt9sZffMdAACPXB/60Id629veVtXrX//6vu7rvu5zrj/+8Y/vyJEj3XTTTdWJb7N717veVdUll1zSjTfeWNUNN9ywI/P5SmgAgEeY3fh4taqv/Mqv7LrrrutFL3pRF154Yddcc00//uM//jlrbrjhhq655ppe8YpXdN9993XllVf21V/91f3Yj/1Y3/qt39orX/nKrrjiih2ZTxgDAHBGnHPOOf30T//055y7++67P+f4yJEjvelNb/q8xx45cuSzd5urXvGKV2z7fLZSAABAwhgAgDPg8OHD3XHHHbs9xhcljAEAIGEMAACVMAYAgEoYAwBA5ePaAAAeeV72hG1+vo9ty9Ncf/31HT16tJ/4iZ/Yluf7UrljDAAACWMAAM6Au+++u6c85Sm98IUv7MlPfnLPf/7z+4Vf+IUuueSSLrjggt7xjnfs9ojCGACAM+PYsWO95CUv6c477+zOO+/s9a9/fb/6q7/aj/7oj/ZDP/RDuz2ePcYAAJwZR44c6aKLLqrqaU97Wpdeemkz00UXXfR5Xw29G9wxBgDgjHjMYx7z2d/POuuszx6fddZZ3X///bs11mcJYwAAyFYKAIBHnm36eLX9RhgDALDjDh8+3B133PHZ4+uvv/6U1174whee4cn+N1spAAAgYQwAAJUwBgB4RFhr7fYIO+6h/o3CGABgnztw4ED33nvvvo7jtVb33ntvBw4ceNDP4c13AAD73KFDhzp+/Hj33HPPbo+yow4cONChQ4ce9OOFMQDAPveoRz2qI0eO7PYYe56tFAAAkDAGAIBKGAMAQCWMAQCgEsYAAFAJYwAAqIQxAABUwhgAACphDAAAlTAGAIBKGAMAQCWMAQCgqnN2ewDYaw5f+/O7PQJ8QXcf2O0JAPYvd4wBACBhDAAAlTAGAIBKGAMAQCWMAQCgEsYAAFBtMYxn5rKZuWtmjs3Mtae4/uUz85aZ+Y2ZeffMfOP2jwoAADvntGE8M2dX11XPqS6srpqZC09a9v3VG9Zaf6a6snr1dg8KAAA7aSt3jJ9VHVtrfWCt9enqxuqKk9as6vEbvz+h+u3tGxEAAHbeVsL4SdWHNx0f3zi32cuqF8zM8eqW6u+c6olm5uqZOTozR++5554HMS4AAOyM7Xrz3VXV9WutQ9U3Vj81M5/33Gut1661Ll5rXXzw4MFtemkAAHjothLGH6nO33R8aOPcZt9ZvaFqrfW26kB13nYMCAAAZ8JWwvi26oKZOTIzj+7Em+tuPmnNh6pLq2bmqZ0IY3slAAB42DhtGK+17q9eXL25el8nPn3iPTPz8pm5fGPZS6q/NTPvqn6meuFaa+3U0AAAsN3O2cqitdYtnXhT3eZzP7Dp9/dWl2zvaAAAcOb45jsAAEgYAwBAJYwBAKASxgAAUAljAACohDEAAFTCGAAAKmEMAACVMAYAgEoYAwBAJYwBAKASxgAAUAljAACohDEAAFTCGAAAKmEMAACVMAYAgEoYAwBAJYwBAKASxgAAUAljAACohDEAAFTCGAAAKmEMAACVMAYAgEoYAwBAJYwBAKASxgAAUAljAACohDEAAFTCGAAAKmEMAACVMAYAgEoYAwBAJYwBAKASxgAAUAljAACohDEAAFTCGAAAKmEMAACVMAYAgEoYAwBAJYwBAKDaYhjPzGUzc9fMHJuZa7/Amr8+M++dmffMzOu3d0wAANhZ55xuwcycXV1X/eXqeHXbzNy81nrvpjUXVP+oumSt9dGZ+aM7NTAAAOyErdwxflZ1bK31gbXWp6sbqytOWvO3quvWWh+tWmv97vaOCQAAO2srYfyk6sObjo9vnNvsydWTZ+bXZubWmbnsVE80M1fPzNGZOXrPPfc8uIkBAGAHbNeb786pLqi+obqq+jcz88STF621XrvWunitdfHBgwe36aUBAOCh20oYf6Q6f9PxoY1zmx2vbl5r3bfW+mD13zoRygAA8LCwlTC+rbpgZo7MzKOrK6ubT1rzHzpxt7iZOa8TWys+sI1zAgDAjjptGK+17q9eXL25el/1hrXWe2bm5TNz+cayN1f3zsx7q7dU/2Ctde9ODQ0AANvttB/XVrXWuqW65aRzP7Dp91V978YPAAA87PjmOwAASBgDAEAljAEAoBLGAABQCWMAAKiEMQAAVMIYAAAqYQwAAJUwBgCAShgDAEAljAEAoBLGAABQCWMAAKiEMQAAVMIYAAAqYQwAAJUwBgCAShgDAEAljAEAoBLGAABQCWMAAKiEMQAAVMIYAAAqYQwAAJUwBgCAShgDAEAljAEAoBLGAABQCWMAAKiEMQAAVMIYAAAqYQwAAJUwBgCAShgDAEAljAEAoBLGAABQCWMAAKiEMQAAVMIYAAAqYQwAAJUwBgCAShgDAEAljAEAoBLGAABQbTGMZ+aymblrZo7NzLVfZN1fm5k1Mxdv34gAALDzThvGM3N2dV31nOrC6qqZufAU6x5XfU/19u0eEgAAdtpW7hg/qzq21vrAWuvT1Y3VFadY94PVK6tPbuN8AABwRmwljJ9UfXjT8fGNc581M8+ozl9r/fwXe6KZuXpmjs7M0XvuuedLHhYAAHbKQ37z3cycVf2L6iWnW7vWeu1a6+K11sUHDx58qC8NAADbZith/JHq/E3HhzbOPeBx1VdVvzQzd1dfU93sDXgAADycbCWMb6sumJkjM/Po6srq5gcurrU+ttY6b611eK11uLq1unytdXRHJgYAgB1w2jBea91fvbh6c/W+6g1rrffMzMtn5vKdHhAAAM6Ec7ayaK11S3XLSed+4Aus/YaHPhYAAJxZvvkOAAASxgAAUAljAACohDEAAFTCGAAAKmEMAACVMAYAgEoYAwBAJYwBAKASxgAAUAljAACohDEAAFTCGAAAKmEMAACVMAYAgEoYAwBAJYwBAKASxgAAUAljAACohDEAAFTCGAAAKmEMAACVMAYAgEoYAwBAJYwBAKASxgAAUAljAACohDEAAFTCGAAAKmEMAACVMAYAgEoYAwBAJYwBAKASxgAAUAljAACohDEAAFTCGAAAKmEMAACVMAYAgEoYAwBAJYwBAKASxgAAUAljAACothjGM3PZzNw1M8dm5tpTXP/emXnvzLx7Zv7zzHzF9o8KAAA757RhPDNnV9dVz6kurK6amQtPWvYb1cVrradXP1v98HYPCgAAO2krd4yfVR1ba31grfXp6sbqis0L1lpvWWt9YuPw1urQ9o4JAAA7ayth/KTqw5uOj2+c+0K+s/pPp7owM1fPzNGZOXrPPfdsfUoAANhh2/rmu5l5QXVx9SOnur7Weu1a6+K11sUHDx7czpcGAICH5JwtrPlIdf6m40Mb5z7HzPyl6vuqP7/W+tT2jAcAAGfGVu4Y31ZdMDNHZubR1ZXVzZsXzMyfqf51dfla63e3f0wAANhZpw3jtdb91YurN1fvq96w1nrPzLx8Zi7fWPYj1WOrm2bmnTNz8xd4OgAA2JO2spWitdYt1S0nnfuBTb//pW2eCwAAzijffAcAAAljAACohDEAAFTCGAAAKmEMAACVMAYAgEoYAwBAJYwBAKASxgAAUAljAACohDEAAFTCGAAAKmEMAACVMAYAgEoYAwBAJYwBAKASxgAAUAljAACohDEAAFTCGAAAKmEMAACVMAYAgEoYAwBAJYwBAKASxgAAUAljAACohDEAAFTCGAAAKmEMAACVMAYAgEoYAwBAJYwBAKASxgAAUAljAACohDEAAFTCGAAAKmEMAACVMAYAgEoYAwBAJYwBAKASxgAAUAljAACohDEAAFRbDOOZuWxm7pqZYzNz7SmuP2Zm/s+N62+fmcPbPSgAAOyk04bxzJxdXVc9p7qwumpmLjxp2XdWH11r/anqX1av3O5BAQBgJ23ljvGzqmNrrQ+stT5d3VhdcdKaK6p/v/H7z1aXzsxs35gAALCzthLGT6o+vOn4+Ma5U65Za91ffaw6dzsGBACAM+GcM/liM3N1dfXG4cdn5q4z+foAD3dT51X/fbfngM/zT/wfxexpX7GVRVsJ449U5286PrRx7lRrjs/MOdUTqntPfqK11mur125lMAA+38wcXWtdvNtzAOxHW9lKcVt1wcwcmZlHV1dWN5+05ubqOzZ+f271i2uttX1jAgDAzjrtHeO11v0z8+LqzdXZ1b9da71nZl5eHV1r3Vz9ZPVTM3Os+h+diGcAAHjYGDd2AR4+ZubqjW1pAGwzYQwAAPlKaAAAqIQxAABUwhgAACphDAAA1Rn+5jsAvnQz85jqr1WH2/Tv9lrr5bs1E8B+JIwB9r43Vh+rbq8+tcuzAOxbPq4NYI+bmTvWWl+123MA7Hf2GAPsfW+dmYt2ewiA/c4dY4A9bmbeW/2p6oOd2Eox1VprPX1XBwPYZ4QxwB43M19xqvNrrd8607MA7GfefAewxz0QwDPzR6sDuzwOwL5ljzHAHjczl8/M+zuxleKXq7ur/7SrQwHsQ8IYYO/7weprqv+21jpSXVrdursjAew/whhg77tvrXVvddbMnLXWekt18W4PBbDf2GMMsPf93sw8tvov1Q0z87vVH+zyTAD7jk+lANjjZubLqk924mPanl89obph4y4yANtEGAM8DMzMH6ueVa3qtrXW/7vLIwHsO/YYA+xxM/M3q3dUf7V6bnXrzLxod6cC2H/cMQbY42bmruprH9g6MTPnVm9da33l7k4GsL+4Ywyw991b/f6m49/fOAfANnLHGGCPm5nXVRdVb+zEHuMrqndv/LTW+he7Nx3A/uHj2gD2vt/c+HnAGzf++7hdmAVg33LHGAAAcscYYM+bmYPVP6yeVh144Pxa6y/u2lAA+5A33wHsfTdUd1ZHqn9S3V3dtpsDAexHtlIA7HEzc/ta65kz8+611tM3zt221vqzuz0bwH5iKwXA3nffxn9/Z2a+qfrt6o/s4jwA+5IwBtj7XjEzT6heUv149fjq7+7uSAD7jzAG2Ps+utb6WPWx6i9UzcwluzsSwP5jjzHAHjczv77WesbpzgHw0LhjDLBHzcyzq6+tDs7M92669Pjq7N2ZCmD/EsYAe9ejq8d24t/qzd9y9z+r5+7KRAD7mDAG2KPWWr9c/fLM/K+11g9vvjYzz6vevzuTAexPvuADYO+78hTn/tEZnwJgn3PHGGCPmpnnVN9YPWlmXrXp0uOr+3dnKoD9SxgD7F2/XR2tLq9u33T+96u/tysTAexjPq4NYI+bmUette47/UoAHgp3jAH2vsMz88+qC6sDD5xca/2J3RsJYP/x5juAve/fVf+qE/uK/0L1uuqnd3UigH3IVgqAPW5mbl9rPXNm/uta66LN53Z7NoD9xFYKgL3vUzNzVvX+mXlx9ZFOfPEHANvIHWOAPW5m/mz1vuqJ1Q9WT6h+eK11664OBrDPCGMAAMhWCoA9a2Zu/mLX11qXn6lZAB4JhDHA3vXs6sPVz1Rvr2Z3xwHY32ylANijZubs6i9XV1VPr36++pm11nt2dTCAfcrnGAPsUWutP1xrvWmt9R3V11THql/a+GQKALaZrRQAe9jMPKb6pk7cNT5cvar6v3dzJoD9ylYKgD1qZl5XfVV1S3XjWuuOXR4JYF8TxgB71Mx8pvqDjcPN/1hPtdZajz/zUwHsX8IYAADy5jsAAKiEMQAAVMIYAAAqYQywJ83MN8/MhQ/ysd81M99+ivOHZ8YnWwB8AT7HGGCHzcx04s3On/kSHvbN1X+s3vulvt5a6zVf6mMAcMcYYEds3J29a+OziO+ovm1m/uvM3DEzr9y07uObfn/uzFw/M19bXV79yMy8c2b+5MbPm2bm9pn5LzPzlC/y2i+bmb+/8fszZ+ZdM/Ou6m9vWvO0mXnHxvO/e2Yu2IH/GQAeVtwxBtg5F1TfUX2ourV6ZvXR6v+ZmW9ea/2HUz1orfXWmbm5+o9rrZ+tmpn/XH3XWuv9M/PnqldXf3ELM/y76sVrrV+ZmR/ZdP67qh9ba90wM4+uzn6QfyPAviGMAXbOb621bp2ZK6pfWmvdUzUzN1T/R3XKMD7ZzDy2+trqphO7Mqp6zBYe98TqiWutX9k49VPVczZ+f1v1fTNzqPq/1lrv3+LfBLBv2UoBsHP+4PRLPucb7Q58gTVnVb+31vrTm36e+lAGW2u9vhPbNf5XdcvMbOXuM8C+JowBdt47qj8/M+fNzNnVVdUvb1z7/2bmqTNzVvVXNj3m96vHVa21/mf1wZl5Xp14M9/MfPXpXnSt9XvV783M122cev4D12bmT1QfWGu9qnpj9fSH9BcC7APCGGCHrbV+p7q2ekv1rur2tdYbNy5f24lPn3hr9TubHnZj9Q9m5jdm5k92Imq/c+NNdO+prtjiy/+N6rqZeWc1m87/9eqOjfNfVb3uQf1xAPvIrLVOvwoAAPY5d4wBACCfSgHwsDUz31c976TTN621/uluzAPwcGcrBQAAZCsFAABUwhgAACphDAAAlTAGAICq/n/Th8wGMKoOHAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 864x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pd.DataFrame({\n",
    "    'route_ids': ml_acc.index.values, \n",
    "    'pred': pred_acc.values, \n",
    "    'ml': ml_acc.values\n",
    "}).plot(kind='bar', x='route_ids', figsize=(12,5))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
